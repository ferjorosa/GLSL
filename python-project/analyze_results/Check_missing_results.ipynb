{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Discre experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import statistics as stats\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "\n",
    "methods = [\n",
    "    \"MEAN\", \n",
    "    \"MICE\", \n",
    "    \"GLFM\", \n",
    "    \"HIVAE\", \n",
    "    \"VBSEM\", \n",
    "    \"glsl_EMPTY\"\n",
    "          ]\n",
    "max_percentage = 6\n",
    "n_runs = 5\n",
    "directories = [\"../../missing_results/discrete/\"]\n",
    "accuracy_error_dfs = []\n",
    "data_names = [\n",
    "        \"hiv_test\", \n",
    "        \"hayes_roth\",\n",
    "        \"balance_scale\", \n",
    "        \"car_evaluation\",\n",
    "        \"nursery\", \n",
    "        \"breast_cancer\", \n",
    "        \"web_phishing\",\n",
    "        \"solar_flare\",\n",
    "        \"zoo\",\n",
    "        \"vote\", \n",
    "        \"spect_heart\",\n",
    "         \"alarm\"\n",
    "]\n",
    "\n",
    "\n",
    "# Iterate through the missing percentage values, and for each dataset, recover the methods' results\n",
    "for i in range(1, max_percentage):\n",
    "    miss_percentage_string = \"0\" + str(i)\n",
    "\n",
    "    df_error_results = pd.DataFrame()\n",
    "\n",
    "    for directory in directories:\n",
    "\n",
    "        for data_name in data_names:\n",
    "            error_results = {\"dataset\": data_name}\n",
    "            for method_name in methods:\n",
    "                json_name = data_name + \"_\" + miss_percentage_string + \"_results_\" + method_name + \".json\"\n",
    "                full_path = directory + data_name + \"/\" + json_name\n",
    "                try:\n",
    "                    with open(full_path) as json_file:\n",
    "                        json_data = json.load(json_file)\n",
    "                        runs_data = json_data[\"runs\"]\n",
    "                        errors = []\n",
    "                        learning_times = []\n",
    "                        for j in range(1, n_runs + 1):\n",
    "                            errors.append(1.0 - runs_data[\"run_\" + str(j)][\"accuracy\"]) \n",
    "\n",
    "                        avg_error = stats.mean(errors)\n",
    "                        #stdev_error = stats.stdev(errors)\n",
    "                        error_results[method_name] = avg_error\n",
    "                \n",
    "                except Exception as e:\n",
    "                    #print(e)\n",
    "                    print(\"[\"+method_name+\"]: \" + full_path)\n",
    "\n",
    "            df_error_results = df_error_results.append(error_results, ignore_index=True)\n",
    "\n",
    "    accuracy_error_dfs.append(df_error_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import statistics as stats\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "\n",
    "methods = [\n",
    "    \"MEAN\", \n",
    "    \"MICE\", \n",
    "    \"GLFM\", \n",
    "    \"HIVAE\", \n",
    "    \"VBSEM\",\n",
    "#     \"glsl_EMPTY\"\n",
    "          ]\n",
    "max_percentage = 6\n",
    "n_runs = 5\n",
    "directories = [\"../../missing_results/discrete/\"]\n",
    "accuracy_error_dfs = []\n",
    "data_names = [\n",
    "        \"coil_42\", \n",
    "        \"news_100\",\n",
    "        \"webkb_336\"\n",
    "]\n",
    "\n",
    "\n",
    "# Iterate through the missing percentage values, and for each dataset, recover the methods' results\n",
    "for i in range(1, max_percentage):\n",
    "    miss_percentage_string = \"0\" + str(i)\n",
    "\n",
    "    df_error_results = pd.DataFrame()\n",
    "\n",
    "    for directory in directories:\n",
    "\n",
    "        for data_name in data_names:\n",
    "            error_results = {\"dataset\": data_name}\n",
    "            for method_name in methods:\n",
    "                json_name = data_name + \"_\" + miss_percentage_string + \"_results_\" + method_name + \".json\"\n",
    "                full_path = directory + data_name + \"/\" + json_name\n",
    "                try:\n",
    "                    with open(full_path) as json_file:\n",
    "                        json_data = json.load(json_file)\n",
    "                        runs_data = json_data[\"runs\"]\n",
    "                        errors = []\n",
    "                        learning_times = []\n",
    "                        for j in range(1, n_runs + 1):\n",
    "                            errors.append(1.0 - runs_data[\"run_\" + str(j)][\"accuracy\"]) \n",
    "\n",
    "                        avg_error = stats.mean(errors)\n",
    "                        #stdev_error = stats.stdev(errors)\n",
    "\n",
    "                        error_results[method_name] = avg_error\n",
    "                \n",
    "                except Exception as e:\n",
    "                    #print(e)\n",
    "                    print(\"[\"+method_name+\"]: \" + full_path)\n",
    "\n",
    "            df_error_results = df_error_results.append(error_results, ignore_index=True)\n",
    "\n",
    "    accuracy_error_dfs.append(df_error_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Continuous experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import statistics as stats\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "\n",
    "methods = [\n",
    "    \"MEAN\", \n",
    "    \"MICE\", \n",
    "    \"GLFM\", \n",
    "    \"HIVAE\", \n",
    "    \"VBSEM\", \n",
    "    \"glsl_EMPTY\"\n",
    "          ]\n",
    "max_percentage = 6\n",
    "n_runs = 5\n",
    "directories = [\"../../missing_results/continuous/\"]\n",
    "accuracy_error_dfs = []\n",
    "data_names = [\n",
    "        \"real_state_valuation\", \n",
    "        \"buddymove\", \n",
    "        \"qsar_fish_toxicity\", \n",
    "        \"qsar_aqua_toxicity\", \n",
    "        \"ilpd\",\n",
    "        \"alcohol\",\n",
    "        \"travel_reviews\",\n",
    "        \"wine_quality_white\", \n",
    "        \"wine\", \n",
    "        \"leaf\", \n",
    "        \"nba\", \n",
    "        \"wdbc\", \n",
    "]\n",
    "\n",
    "\n",
    "# Iterate through the missing percentage values, and for each dataset, recover the methods' results\n",
    "for i in range(1, max_percentage):\n",
    "    miss_percentage_string = \"0\" + str(i)\n",
    "\n",
    "    df_error_results = pd.DataFrame()\n",
    "\n",
    "    for directory in directories:\n",
    "\n",
    "        for data_name in data_names:\n",
    "            error_results = {\"dataset\": data_name}\n",
    "            for method_name in methods:\n",
    "                json_name = data_name + \"_\" + miss_percentage_string + \"_results_\" + method_name + \".json\"\n",
    "                full_path = directory + data_name + \"/\" + json_name\n",
    "                try:\n",
    "                    with open(full_path) as json_file:\n",
    "                        json_data = json.load(json_file)\n",
    "                        runs_data = json_data[\"runs\"]\n",
    "                        errors = []\n",
    "                        learning_times = []\n",
    "                        for i in range(1, n_runs + 1):\n",
    "                            #i=1\n",
    "                            errors.append(1.0 - runs_data[\"run_\" + str(i)][\"nrmse\"]) \n",
    "\n",
    "                            avg_error = stats.mean(errors)\n",
    "                            #stdev_error = stats.stdev(errors)\n",
    "\n",
    "                        error_results[method_name] = avg_error\n",
    "                \n",
    "                except Exception as e:\n",
    "                    #print(e)\n",
    "                    print(\"[\"+method_name+\"]: \" + full_path)\n",
    "\n",
    "            df_error_results = df_error_results.append(error_results, ignore_index=True)\n",
    "\n",
    "    accuracy_error_dfs.append(df_error_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HIVAE]: ../../missing_results/continuous/geo_music/geo_music_01_results_HIVAE.json\n",
      "[HIVAE]: ../../missing_results/continuous/geo_music/geo_music_02_results_HIVAE.json\n",
      "[HIVAE]: ../../missing_results/continuous/geo_music/geo_music_03_results_HIVAE.json\n",
      "[HIVAE]: ../../missing_results/continuous/geo_music/geo_music_04_results_HIVAE.json\n",
      "[HIVAE]: ../../missing_results/continuous/geo_music/geo_music_05_results_HIVAE.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import statistics as stats\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "\n",
    "methods = [\n",
    "    \"MEAN\", \n",
    "    \"MICE\", \n",
    "    \"GLFM\", \n",
    "    \"HIVAE\", \n",
    "    \"VBSEM\",\n",
    "#     \"glsl_EMPTY\"\n",
    "]\n",
    "max_percentage = 6\n",
    "n_runs = 5\n",
    "directories = [\"../../missing_results/continuous/\"]\n",
    "accuracy_error_dfs = []\n",
    "data_names = [\n",
    "    \"waveform\", \n",
    "    \"100_plants\", \n",
    "    \"geo_music\"\n",
    "]\n",
    "\n",
    "\n",
    "# Iterate through the missing percentage values, and for each dataset, recover the methods' results\n",
    "for i in range(1, max_percentage):\n",
    "    miss_percentage_string = \"0\" + str(i)\n",
    "\n",
    "    df_error_results = pd.DataFrame()\n",
    "\n",
    "    for directory in directories:\n",
    "\n",
    "        for data_name in data_names:\n",
    "            error_results = {\"dataset\": data_name}\n",
    "            for method_name in methods:\n",
    "                json_name = data_name + \"_\" + miss_percentage_string + \"_results_\" + method_name + \".json\"\n",
    "                full_path = directory + data_name + \"/\" + json_name\n",
    "                try:\n",
    "                    with open(full_path) as json_file:\n",
    "                        json_data = json.load(json_file)\n",
    "                        runs_data = json_data[\"runs\"]\n",
    "                        errors = []\n",
    "                        learning_times = []\n",
    "                        for i in range(1, n_runs + 1):\n",
    "                            errors.append(1.0 - runs_data[\"run_\" + str(i)][\"nrmse\"]) \n",
    "\n",
    "                        avg_error = stats.mean(errors)\n",
    "                        #stdev_error = stats.stdev(errors)\n",
    "\n",
    "                        error_results[method_name] = avg_error\n",
    "                \n",
    "                except Exception as e:\n",
    "                    #print(e)\n",
    "                    print(\"[\"+method_name+\"]: \" + full_path)\n",
    "\n",
    "            df_error_results = df_error_results.append(error_results, ignore_index=True)\n",
    "\n",
    "    accuracy_error_dfs.append(df_error_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Mixed experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import statistics as stats\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "\n",
    "methods = [\n",
    "    \"MEAN\", \n",
    "    \"MICE\", \n",
    "    \"GLFM\", \n",
    "    \"HIVAE\", \n",
    "    \"VBSEM\", \n",
    "    \"glsl_EMPTY\"\n",
    "          ]\n",
    "max_percentage = 6\n",
    "n_runs = 5\n",
    "directories = [\"../../missing_results/mixed/\"]\n",
    "accuracy_error_dfs = []\n",
    "data_names = [\n",
    "        \"haberman\", \n",
    "        \"iris\", \n",
    "        \"user_knowledge\",\n",
    "        \"vertebral\", \n",
    "        \"ecoli\", \n",
    "        \"planning_relax\", \n",
    "        \"thoracic_surgery\",\n",
    "        \"vehicle\", \n",
    "        \"thyroid\",\n",
    "        \"parkinsons\", \n",
    "        \"autos\", \n",
    "        \"ionosphere\"\n",
    "]\n",
    "\n",
    "\n",
    "# Iterate through the missing percentage values, and for each dataset, recover the methods' results\n",
    "for i in range(1, max_percentage):\n",
    "    miss_percentage_string = \"0\" + str(i)\n",
    "\n",
    "    df_error_results = pd.DataFrame()\n",
    "\n",
    "    for directory in directories:\n",
    "\n",
    "        for data_name in data_names:\n",
    "            error_results = {\"dataset\": data_name}\n",
    "            for method_name in methods:\n",
    "                json_name = data_name + \"_\" + miss_percentage_string + \"_results_\" + method_name + \".json\"\n",
    "                full_path = directory + data_name + \"/\" + json_name\n",
    "                try:\n",
    "                    with open(full_path) as json_file:\n",
    "                        json_data = json.load(json_file)\n",
    "                        runs_data = json_data[\"runs\"]\n",
    "                        errors = []\n",
    "                        learning_times = []\n",
    "                        for j in range(1, n_runs + 1):\n",
    "                            errors.append(1.0 - runs_data[\"run_\" + str(j)][\"average_error\"]) \n",
    "\n",
    "                        avg_error = stats.mean(errors)\n",
    "                        #stdev_error = stats.stdev(errors)\n",
    "\n",
    "                        error_results[method_name] = avg_error\n",
    "                \n",
    "                except Exception as e:\n",
    "                    #print(e)\n",
    "                    print(\"[\"+method_name+\"]: \" + full_path)\n",
    "\n",
    "            df_error_results = df_error_results.append(error_results, ignore_index=True)\n",
    "\n",
    "    accuracy_error_dfs.append(df_error_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import statistics as stats\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "\n",
    "methods = [\n",
    "    \"MEAN\", \n",
    "    \"MICE\", \n",
    "    \"GLFM\", \n",
    "    \"HIVAE\", \n",
    "    \"VBSEM\",\n",
    "#     \"glsl_EMPTY\"    \n",
    "]\n",
    "max_percentage = 6\n",
    "n_runs = 5\n",
    "directories = [\"../../missing_results/mixed/\"]\n",
    "accuracy_error_dfs = []\n",
    "data_names = [\n",
    "    \"qsar_biodeg\",\n",
    "    \"housing_prices\",\n",
    "    \"census_india\"\n",
    "]\n",
    "\n",
    "\n",
    "# Iterate through the missing percentage values, and for each dataset, recover the methods' results\n",
    "for i in range(1, max_percentage):\n",
    "    miss_percentage_string = \"0\" + str(i)\n",
    "\n",
    "    df_error_results = pd.DataFrame()\n",
    "\n",
    "    for directory in directories:\n",
    "\n",
    "        for data_name in data_names:\n",
    "            error_results = {\"dataset\": data_name}\n",
    "            for method_name in methods:\n",
    "                json_name = data_name + \"_\" + miss_percentage_string + \"_results_\" + method_name + \".json\"\n",
    "                full_path = directory + data_name + \"/\" + json_name\n",
    "                try:\n",
    "                    with open(full_path) as json_file:\n",
    "                        json_data = json.load(json_file)\n",
    "                        runs_data = json_data[\"runs\"]\n",
    "                        errors = []\n",
    "                        learning_times = []\n",
    "                        for j in range(1, n_runs + 1):\n",
    "                            errors.append(1.0 - runs_data[\"run_\" + str(j)][\"average_error\"]) \n",
    "\n",
    "                        avg_error = stats.mean(errors)\n",
    "                        #stdev_error = stats.stdev(errors)\n",
    "\n",
    "                        error_results[method_name] = avg_error\n",
    "                \n",
    "                except Exception as e:\n",
    "                    #print(e)\n",
    "                    print(\"[\"+method_name+\"]: \" + full_path)\n",
    "\n",
    "            df_error_results = df_error_results.append(error_results, ignore_index=True)\n",
    "\n",
    "    accuracy_error_dfs.append(df_error_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
